<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>CS205 Real Time Image Stitching</title>

    <!-- Bootstrap core CSS -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/scrolling-nav.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link rel="shortcut icon" type="image/x-icon" href="img/seas-logo.ico"/>

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Real-Time Image Stitching</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#overview">Introduction</a>
            </li>
            <br>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#eda">Design Approach</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#follower">Performance Results</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#playlist">Discussions</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <header class="text-white">
      <div class="container text-center">
        <h1>Real-Time Image Stitching</h1>
        <p class="lead">CS205 Computing Foundations for Computational Science Final Project</p>
        <p id="info">Group 4: Weihang Zhang, Xuefeng Peng, Jiacheng Shi and Ziqi Guo</p>
        <p id="info">Harvard University, Spring 2018</p>
      </div>
    </header>

    <section id="overview">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h1>Introduction</h1><br>
            <h4>Problem Statement</h4>
            <br>
            <p>In this project, we want to use big compute techniques to parallelize the algorithms of <strong>image stitching</strong>, so that we can stream videos from adjascent camera into a single panoramic view.</p>
            <p>Image stitching or photo stitching is the process of combining multiple photographic images with overlapping fields of view to produce a segmented panorama or high-resolution image (example below).</p>
            <br><br>
            <p class="img"><img src="img/stitching_example.jpg" height="300" width="750"></p>
            <br><br>
            <h4>Procedures of Image Stitching</h4>
            <br>
            <p>Image stitching is a rather complicated application in computer vision. It is composed of several key stages, some of which involve heavy computation. We will give an intuitive explanation of each of the key procedures below. Please follow the links provided for more technical details, and please refer to the Design Approach section for a complexity profiling of these tasks.</p>
            <ol>
              <li><strong>Keypoint Detection and Description</strong></li><br>
              <p>As a first step, keypoints on the two images you want to stitch together need to be identified. These keypoints usually correspond to the most distinguish features of an image, such as corners and edges of an object. There are several famous algorithms that dedicately achieve this task, including Harris Corner Detection, Scale Invariant Feature Transform (SIFT) and Speed-Up Robust Features (SURF). SIFT and SURF are the state-of-the-art due to their robustness.</p>
              <p>Not only do these algorithms identify the keypoints, they will also generate a descriptor vector for each of the keypoints. These descriptors will capture information about the keypoints' location, orientation and relation to their surroundings.</p>
              <li><strong>Keypoint Matching</strong></li><br>
              <p>After keypoint detection, each image will have a set of keypoints together with their descriptor vectors. We will then need to establish matching relations between these descriptors. Most methods are based on Euclidean distance between descriptors. For each keypoint in image 1, if its best match is significantly better than the second best match, than we consider the best match valid.</p>
              <li><strong>Transformation Estimation</strong></li>
              <p>Once we have establish matching keypoints between images, we want to estimate a transformation matrix H that will be used to warp the image. Normally, Random Sample Consensus (RANSAC) will be used to derive reliable transformation matrix after removing false matches. The algorithm basically iteratively try out different match combinations and only keep the one that is the best-fitting to the matches.</p>
              <li><strong>Warping</strong></li>
              <p>With the transformation matrix, we can project the image to the right to the plane that the image to the left is at. This is called warping.</p>
              <li><strong>Stitching</strong></li>
              <p>Finally, we have the original image 1, and the warped image 2. We can stitch them together by placing pixels from both images on a blank canvas.</p>
              <li><strong>Border Blending</strong></li>
              <p>Border blending is to smooth out the differences in light and hue across the stitching seam, so that the stitched image can look more homogeneous.</p>
            </ol>
            <br><br>
            <h4>Need for High Performance Computing</h4>
            <p>The key idea of our project is to focus on the word ‘real-time’. Although there are existing algorithms for the application, doing it in ‘real-time’ can still be challenging.</p>
            <p>Imagine the scenario where we need a real-time panorama streaming view, this would require the backend application to stitch the view of different cameras together frame by frame. For a laggy video of 5 frames per second, we will need processing time of at most 0.2 seconds for each pair of images. This would be very difficult to achieve with regular computational resources. With a faster stitching process of one pair of images, we can process more image pairs per second, which would result in a higher Frames Per Second (FPS). FPS is a direct measure of how fluid the video looks to human eyes.</p>
            <p>In addition, with high performance computing, we can stitch images of higher resolution, at a visually fluid speed. This is the whole motivation of parallelizing the task of image stitching.</p>


            <br><br>
            <h4>Challenges</h4>
            <p>There are several challenges associated with our project:</p>
            <ul>
              <li>Some algorithm such as SIFT or SURF is rather complicated to understand as well as to re-implement. They are not composed solely of independent loops, but have many data dependencies that need to be dismantled before parallelization.</li>
              <li>The desirable speedup might be challenging to achieve. The sequential version will take only a few seconds to run once. This means overheads such as memory access, synchronization and communication are by no means negligible. Speeding it up to achieve multiple frames per second entails careful optimization of overheads.</li>
              <li>The program might be heavily memory bound, as a high resolution image will have millions of pixels, and we can potentially find a large amount of keypoints. Accessing and communicating the original images and these keypoints together with their descriptors will add to the execution time.</li>
              <li>Our parallelization target is not a single algorithm. It is a sequence of algorithms achieving different tasks. We need to consider the possibility of task-level scheduling and parallelization of these different tasks.</li>
            </ul>
            <p></p>



          </div>
        </div>
      </div>
    </section>

    <section id="eda" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h1>Design Approach</h1><br>
            <h4>Code and Data Source</h4>
            <p>We base our parallelization based on a sequential implementation of keypoint detection using Speed-Up Robust Features (SURF) as well as matching. The code can be found at <a href="https://github.com/abhinavgupta/SURF">https://github.com/abhinavgupta/SURF</a>.</p>
            <p>To finish up the whole stitching process, we implemented our own transformation estimation, warping and stitching algorithm. For transformation estimation, we relied on OpenCV's implementation as this step is not one of the computationally heaviest ones. For warping and stitching, we implemented them without using any vision libraries so that we can have full control of the parallelization.</p>
            <p>As for data, we shot images and videos on 2 <a href="https://www.amazon.com/Logitech-Laptop-Webcam-Design-360-Degree/dp/B004YW7WCY/ref=sr_1_8?s=pc&ie=UTF8&qid=1525394553&sr=1-8&keywords=logitech+webcam">Logitech HD Laptop Webcam C615</a>. It is capable of shooting up to 1080p video.</p>

            <br><br>

            <h4>Profiling</h4>

            <br><br>

            <h4>Software Design Overview</h4>
            <br>
            <h5>Parallelization Targets</h5>
            <p>Based on the profiling results shown above, we can see that <strong>keypoint detection</strong>, <strong>descriptor extraction</strong> and <strong>warping</strong> are the computationally heaviest and thus should be parallelized the most.</p>
            <br>
            <h5>Technologies</h5>
            <ul>
              <li><strong>Programming language</strong>: C++</li>
              <li><strong>Tools: </strong>OpenACC, OpenMP, std::thread</li>
            </ul>
            <br>
            <h5>Programming Models</h5>
            <p>We will use several parallel computing paradigms and compare their performance:</p>
            <p>
            <ul>
              <li><strong>Shared Memory Parallelization (OpenMP)</strong></li>
              <p>For shared memory parallelization, we just need to add directives to loops that do not have sequential dependence.
              <li><strong>GPU Acceleration (OpenACC)</strong></li>
              <p>GPU acceleration is very suitable for this type of task. The many cores in GPU provide fundamentally larger computing power. However, we need to pay special attention to the overhead of making memory copies in order to achieve high speedup.</p>
              <li><strong>Advanced Feature: Task-Level Parallelization (Threading)</strong></li>
              <p>The whole task of image stitching can be broken down to various stages. In addition to the algorithms mentioned previously, we still need to extract frames from webcam video stream, and output video from stitched images. By pipelining the different stages with the multiple CPU threads available, we can achieve task-level parallelization so that the execution time will be decided by the bottleneck of the pipeline.</p>
              <li><strong>Hybrid Parallelization</strong></li>
              <p>The previous three approaches can be integrated to a great extent. While the CPU threads are pipelined to handle differen tasks, each task can be parallelized at a procedure/loop level with either OpenACC or OpenMP. We just need to figure out the optimal combination of these approaches.</p>
            </ul>
            <br>
            <h5>Parallelism Taxonomy</h5>
            <ul>
              <li><strong>Types of applications</strong>: big compute with high throughput data</li>
              <li><strong>Levels of parallelism</strong>: task level, procedure level, loop level</li>
              <li><strong>Types of paralellism</strong>: function, pipeline, data</li>
              <li><strong>Parallel execution model</strong>: Multiple Program, Multiple Data (MPMD)</li>
            </ul>
            <br><br>
            <h4>Parallization Details</h4>

          </div>
        </div>
      </div>
    </section>

    <section id="follower">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h1>Performance Results</h1><br>
            <h4>Evaluation Approach</h4>
            <p>To evaluate the performance of our parallelized program, we will use videos captured at different resolutions. We will use the average execution time of each frame to calculate speedup, and use the FPS as a measure of throughput.</p>
            <p>As for testing platform, we will use the <strong>AWS EC2 t2.2xlarge instance</strong> for baseline and shared memory parallel program. For GPU involved programs, we will evaluate the performance on two devices, a <strong>local PC</strong> with GPU and an <strong>AWS EC2 g3.4xlarge</strong> instance. The specifications of the local PC in comparison to the AWS instance are tabulated below:</p>
            <table class="table table-hover table-striped">
              <caption>Table 1. Device specifications for GPU programs</caption>
              <thead>
              <tr>
                <th scope="col">Variable Name</th>
                <th scope="col">Local PC</th>
                <th scope="col">AWS g3.4xlarge</th>
              </tr>
              </thead>
              <tbody>
              <tr>
                <th scope="row">Operating System</th>
                <td>Ubuntu 16.04</td>
                <td>Ubuntu 16.04</td>
              </tr>
              <tr>
                <th scope="row">vCPU</th>
                <td>8</td>
                <td>8</td>
              </tr>
              <tr>
                <th scope="row">GPU model</th>
                <td>NVIDIA GeForce GTX 1070</td>
                <td>NVIDIA Tesla M60</td>
              </tr>
              <tr>
                <th scope="row">GPU architecture</th>
                <td>Pascal</td>
                <td>Maxwell 2.0</td>
              </tr>
              <tr>
                <th scope="row">Core clock / boost Clock (MHz)</th>
                <td>1506/1683</td>
                <td>930/1180</td>
              </tr>
              <tr>
                <th scope="row">Floating-point performance (gflops)</th>
                <td>6463</td>
                <td>4833</td>
              </tr>
              </tbody>
            </table>
            <p>All used codes and test cases are documented with detailed instructions, which can be found at our <a href="https://github.com/ziqiguo/CS205-ImageStitching">Github repository</a>.</p>
            <br><br>
            <h4>Serial Version</h4>
            <h4>Shared Memory Parallelization with OpenMP</h4>
            Time break-down, speedup, FPS, scalability, overhead
            <h4>GPU Parallelization with OpenACC</h4>
            <h4>Task-level Parallelization</h4>
            <h4>Comparison</h4>
          </div>
        </div>
      </div>
    </section>

    <section id="playlist" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto">
            <h1>Discussions</h1><br>
            <h4>Goals Achieved</h4>
            <h4>Application</h4>
            <h4>Limitation and Future Work</h4>
            <h4></h4>


          </div>
        </div>
      </div>
    </section>


    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Copyright &copy; Harvard CS205 2018 Spring Group 7</p>
        <p class="m-0 text-center text-white">A project by <a href="https://www.linkedin.com/in/jiacshi/">Jiacheng Shi</a>, <a href="https://www.linkedin.com/in/tonyzhanguiuc/">Weihang Zhang</a>, <a href="https://www.linkedin.com/in/xuefengpeng/">Xuefeng Peng</a> and <a href="https://www.linkedin.com/in/ziqi-guo-974aa69a/">Ziqi Guo</a></p>
        <p class="m-0 text-center text-white">Visit <a href="https://github.com/ziqiguo/CS205-ImageStitching">Github Repository</a></p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>


    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Plotting Library -->
    <script src="vendor/plotly-latest.min.js"></script>

    <!-- Custom JavaScript for this theme -->
    <script src="js/scrolling-nav.js"></script>
    <script src="js/plots.js"></script>


  </body>

</html>
